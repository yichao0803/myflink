# 数据仓库介绍和建立步骤
## 1、数据仓库概述
数据仓库是一个面向主题的（Subject Oriented）、集成的（Integrate）、相对稳定的（Non-Volatile）、反应历史变化（Time Variant）的数据集合，用于支持管理决策。

数据仓库是伴随着企业信息化发展起来的，在企业信息化的过程中，随着信息化工具的升级和新工具的应用，数据量变的越来越大，数据格式越来越多，决策要求越来越苛刻，数据仓库技术也在不停的发展。

数据仓库的趋势：

- 实时数据仓库以满足实时化&自动化决策需求；
- 大数据&数据湖以支持大量&复杂数据类型（文本、图像、视频、音频）

## 2、数据仓库架构的演变

数据仓库概念是Inmon于1990年提出并给出了完整的建设方法。随着互联网时代来临，数据量暴增，开始使用大数据工具来替代经典数仓中的传统工具。此时仅仅是工具的取代，架构上并没有根本的区别，可以把这个架构叫做**离线大数据架构**。

后来随着业务实时性要求的不断提高，人们开始在离线大数据架构基础上加了一个加速层，使用流处理技术直接完成那些实时性要求较高的指标计算，这便是**Lambda架构**。

再后来，实时的业务越来越多，事件化的数据源也越来越多，实时处理从次要部分变成了主要部分，架构也做了相应调整，出现了以实时事件处理为核心的**Kappa架构**。

![image](E:\GitOsChina\myflink\image\data-wareHouse-01.png)

### 2.1离线大数据架构

数据源通过离线的方式导入到离线数仓中。

下游应用根据业务需求选择直接读取DM或加一层数据服务，比如mysql 或 redis。

数据仓库从模型层面分为三层：

- ODS，操作数据层，保存原始数据；
- DWD，数据仓库明细层，根据主题定义好事实与维度表，保存最细粒度的事实数据；
- DM，数据集市/轻度汇总层，在DWD层的基础之上根据不同的业务需求做轻度汇总；

典型的数仓存储是HDFS/Hive，ETL可以是MapReduce脚本或HiveSQL。

![image](https://yqfile.alicdn.com/600870e5a3496093d7d49a0e994ccc8b4625b1b8.png)

### 2.2 Lambda架构

随着大数据应用的发展，人们逐渐对系统的实时性提出了要求，为了计算一些实时指标，就在原来离线数仓的基础上增加了一个实时计算的链路，并对数据源做流式改造（即把数据发送到消息队列），实时计算去订阅消息队列，直接完成指标增量的计算，推送到下游的数据服务中去，由数据服务层完成离线&实时结果的合并。

> 注：流处理计算的指标批处理依然计算，最终以批处理为准，即每次批处理计算后会覆盖流处理的结果。（**这仅仅是流处理引擎不完善做的折中**）

**Lambda架构问题：**

- 1.同样的需求需要开发两套一样的代码
  这是Lambda架构最大的问题，两套代码不仅仅意味着开发困难（同样的需求，一个在批处理引擎上实现，一个在流处理引擎上实现，还要分别构造数据测试保证两者结果一致），后期维护更加困难，比如需求变更后需要分别更改两套代码，独立测试结果，且两个作业需要同步上线。
- 2.资源占用增多：同样的逻辑计算两次，整体资源占用会增多（多出实时计算这部分）
  ![image](https://yqfile.alicdn.com/e1c349f18291af1fd287696b3072592f8a1f7e40.png)

### 2.3 Kappa架构

Lambda架构虽然满足了实时的需求，但带来了更多的开发与运维工作，其架构背景是流处理引擎还不完善，流处理的结果只作为临时的、近似的值提供参考。后来随着Flink等流处理引擎的出现，流处理技术很成熟了，这时为了解决两套代码的问题，LickedIn 的Jay Kreps提出了Kappa架构

Kappa架构可以认为是Lambda架构的简化版（只要移除lambda架构中的批处理部分即可）。

在Kappa架构中，需求修改或历史数据重新处理都通过上游重放完成。

Kappa架构最大的问题是流式重新处理历史的吞吐能力会低于批处理，但这个可以通过增加计算资源来弥补。

![image](https://yqfile.alicdn.com/7a761d6f33ff180b13ee186e56d80f30de30229b.png)

**Kappa架构的重新处理过程**

重新处理是人们对Kappa架构最担心的点，但实际上并不复杂：

- 1.选择一个具有重放功能的、能够保存历史数据并支持多消费者的消息队列，根据需求设置历史数据保存的时长，比如Kafka，可以保存全部历史数据。
- 2.当某个或某些指标有重新处理的需求时，按照新逻辑写一个新作业，然后从上游消息队列的最开始重新消费，把结果写到一个新的下游表中。
- 3.当新作业赶上进度后，应用切换数据源，读取2中产生的新结果表。
- 4.停止老的作业，删除老的结果表。

![image](https://yqfile.alicdn.com/de6ec3c9a124aafac92807227918be100c490de2.png)

### 2.4 Lambda架构与Kappa架构的对比

| 对比项         | Lambda架构                                           | Kappa架构                                                |
| :------------- | :--------------------------------------------------- | :------------------------------------------------------- |
| 实时性         | 实时                                                 | 实时                                                     |
| 计算资源       | 批和流同时运行，资源开销大                           | 只有流处理，仅针对新需求开发阶段运行两个作业，资源开销小 |
| 重新计算时吞吐 | 批式全量处理，吞吐较高                               | 流式全量处理，吞吐较批处理低                             |
| 开发、测试     | 每个需求都需要两套不同代码，开发、测试、上线难度较大 | 只需实现一套代码，开发、测试、上线难度相对较小           |
| 运维成本       | 维护两套系统（引擎），运维成本大                     | 只需维护一套系统（引擎），运维成本小                     |

在真实的场景中，很多时候**并不是完全规范的Lambda架构或Kappa架构**，可以是两者的混合，比如大部分实时指标使用Kappa架构完成计算，少量关键指标（比如金额相关）使用Lambda架构用批处理重新计算，增加一次校对过程。（1）

Kappa架构并不是中间结果完全不落地，现在很多大数据系统都需要支持机器学习（离线训练），所以实时中间结果需要落地对应的存储引擎供机器学习使用，另外有时候还需要对明细数据查询，这种场景也需要把实时明细层写出到对应的引擎中。（2）参考后面的案例

另外，随着数据多样性的发展，数据仓库这种提前规定schema的模式显得越来难以支持灵活的探索&分析需求，这时候便出现了一种数据湖技术，即把原始数据全部缓存到某个大数据存储上，后续分析时再根据需求去解析原始数据。简单的说，数据仓库模式是schema on write，数据湖模式是schema on read。（3）

![image](https://yqfile.alicdn.com/b4ea56277037e32cb0970bf0c2ae15df8e10525e.png)

## 3、数据仓库建立步骤

### 3.1 系统分析，确定主题

建立**数据仓库**的第一个步骤就是通过与业务部门的充分交流，了解建立**数据仓库**所要解决的问题的真正含义，确定各个主题下的查询分析要求。

业务人员往往会罗列出很多想解决的问题，信息部门的人员应该对这些问题进行分类汇总，确定**数据仓库**所实现的业务功能。一旦确定问题以后，信息部门的人员还需要确定一下几个因素：

* 操作出现的频率，即业务部门每隔多长时间做一次查询分析。
  
* 在系统中需要保存多久的数据，是一年、两年还是五年、十年。
  
* 用户查询数据的主要方式，如在时间维度上是按照自然年，还是财政年。
  
* 用户所能接受的响应时间是多长、是几秒钟，还是几小时。

由于双方在理解上的差异，确定问题和了解问题可能是一个需要多次往复的过程，信息部门的人员可能需要做一些原型演示给业务部门的人员看，以最终确定系统将要实现的功能确实是业务部门所需要的。

### 3.2 选择满足数据仓库系统要求的软件平台

在**[数据仓库](https://link.zhihu.com/?target=http%3A//www.ciotimes.com/bi/sjck/)**所要解决的问题确定后，第二个步骤就是选择合适的软件平台，包括数据库、建模工具、分析工具等。这里有许多因素要考虑，如系统对数据量、响应时间、分析功能的要求等，以下是一些公认的选择标准：

* 厂商的背景和支持能力，能否提供全方位的技术支持和咨询服务。
* 数据库对大数据量（TB级）的支持能力。
* 数据库是否支持并行操作。
* 能否提供**数据仓库**的建模工具，是否支持对**元数据**的管理。
* 能否提供支持大数据量的数据加载、转换、传输工具（ETT）。
* 能否提供完整的决策支持工具集，满足**数据仓库**中各类用户的需要。

### 3.3 建立数据仓库的逻辑模型

具体步骤如下：
* （1）确定建立**数据仓库**逻辑模型的基本方法。

* （2）基于主题视图，把主题视图中的数据定义转到逻辑数据模型中。

* （3）识别主题之间的关系。

* （4）分解多对多的关系。

* （5）用范式理论检验逻辑数据模型。

* （6）由用户审核逻辑数据模型。

### 3.4 逻辑数据模型转化为数据仓库数据模型

具体步骤如下：

* （1）删除非战略性数据：**[数据仓库](https://link.zhihu.com/?target=http%3A//www.ciotimes.com/bi/sjck/)**模型中不需要包含逻辑数据模型中的全部数据项，某些用于操作处理的数据项要删除。
* （2）增加时间主键：**数据仓库**中的数据一定是时间的快照，因此必须增加时间主键。
* （3）增加派生数据：对于用户经常需要分析的数据，或者为了提高性能，可以增加派生数据。
* （4）加入不同级别粒度的汇总数据：数据粒度代表数据细化程度，粒度越大，数据的汇总程度越高。粒度是**数据仓库**设计的一个重要因素，它直接影响到驻留在**数据仓库**中的数据量和可以执行的查询类型。显然，粒度级别越低，则支持的查询越多；反之，能支持的查询就有限。


对数据操作的效率与能得到数据的详细程度是一对矛盾，通常，人们希望建成的系统既有较高的效率，又能得到所需的详细资料。实施**数据仓库**的一个重要原则就是不要试图包括所有详细数据，因为90%的分析需求是在汇总数据上进行的。试图将粒度细化到最低层，只会增加系统的开销，降低系统的性能。

### 3.5 数据仓库数据模型优化

**数据仓库**设计时，性能是一项主要考虑因素。在**数据仓库**建成后，也需要经常对其性能进行监控，并随着需求和数据量的变更进行调整。
    优化**数据仓库**设计的主要方法是：
* 合并不同的数据表。
* 通过增加汇总表避免数据的动态汇总。
* 通过冗余字段减少表连接的数量，不要超过3~5个。
* 用ID代码而不是描述信息作为键值。
* 对数据表做分区。
### 3.6 数据清洗转换和传输

由于业务系统所使用的软硬件平台不同，编码方法不同，业务系统中的数据在加载到**[数据仓库](https://link.zhihu.com/?target=http%3A//www.ciotimes.com/bi/sjck/)**之前，必须进行数据的清洗和转换，保证**数据仓库**中数据的一致性。


​    在设计**数据仓库**的数据加载方案时，必须考虑以下几项要求：
* 加载方案必须能够支持访问不同的数据库和文件系统。
* 数据的清洗、转换和传输必须满足时间要求，能够在规定的时间范围内完成。
* 支持各种转换方法，各种转换方法可以构成一个工作流。
* 支持增量加载，只把自上一次加载以来变化的数据加载到**数据仓库**。
### 3.7 开发数据仓库的分析应用

建立**数据仓库**的最终目的是为业务部门提供决策支持能力，必须为业务部门选择合适的工具实现其对**数据仓库**中的数据进行分析的要求。
    信息部门所选择的开发工具必须能够：
* 满足用户的全部分析功能要求。**数据仓库**中的用户包括了企业中各个业务部门，他们的业务不同，要求的分析功能也不同。如有的用户只是简单的分析报表，有些用户则要求做预测和趋势分析。
* 提供灵活的表现方式。分析的结果必须能够以直观、灵活的方式表现，支持复杂的图表。使用方式上，可以是客户机/服务器方式，也可以是浏览器方式。

事实上，没有一种工具能够满足**数据仓库**的全部分析功能需求，一个完整的**数据仓库**系统的功能可能是由多种工具来实现，因此必须考虑多个工具之间的接口和集成性问题，对于用户来说，希望看到的是一致的界面。
### 3.8 数据仓库的管理
只重视**数据仓库**的建立，而忽视**数据仓库**的管理必然导致**数据仓库**项目的失败。**数据仓库**管理主要包括数据库管理和**元数据**管理。
    数据库管理需要考以下几个方面：
* 安全性管理。**数据仓库**中的用户只能访问到他的授权范围内的数据，数据在传输过程中的加密策略。
* **数据仓库**的备份和恢复。**数据仓库**的大小和备份的频率直接影响到备份策略。
* 如何保证**数据仓库**系统的可用性，硬件还是软件方法。
* 数据老化。设计**数据仓库**中数据的存放时间周期和对过期数据的老化方法，如历史数据只保存汇总数据，当年数据保存详细记录。

然而，**元数据**管理贯穿于整个系统的建设过程中，**元数据**是描述数据的数据。在数据采集阶段，**元数据**主要包括下列信息：
* 源数据的描述定义：类型、位置、结构。
* 数据转换规则：编码规则、行业标准。
* 目标**数据仓库**的模型描述：星型/雪花模型定义，维/事实结构定义。
* 源数据到目标**数据仓库**的映射关系：函数/表达式定义。
* 代码：生成转换程序、自动加载程序等。

在数据管理阶段，**元数据**主要包括下列信息：
* 汇总数据的描述：汇总/聚合层次、物化视图结构定义。
* 历史数据存储规则：位置、存储粒度。
* 多维数据结构描述：立方体定义、维结构、度量值、钻取层次定义等。

在数据展现阶段，**元数据**主要包括以下信息：
* 报表的描述：报表结构的定义。
* 统计函数的描述：各类统计分析函数的定义。
* 结果输出的描述：图、表输出的定义。

**元数据**不但是独立存放，而且对用户是透明的，标准**[元数据](https://link.zhihu.com/?target=http%3A//www.ciotimes.com/bi/sjck/)**之间可以互相转换。

## 4、参考资料

* [数据仓库介绍与实时数仓案例](https://yq.aliyun.com/articles/691541)


