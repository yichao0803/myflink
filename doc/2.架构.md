# 2.Architecture

- [2.Architecture](#2architecture)
  * [2.1 Layered APIs](#21-layered-apis)
    + [a. Stateful Stream Processing](#a-stateful-stream-processing)
    + [b. DataStream API](#b-datastream-api)
    + [c. SQL & Table API](#c-sql-table-api)
  * [2.2 Components of a Flink Setup](#22-components-of-a-flink-setup)
  * [2.3 Task Execution](#23-task-execution)
    + [a. Operators  任务和算子链](#a-operators-任务和算子链)
    + [b. Tasks](#b-tasks)
      - [b1. Setting Parallelism(设置并行度)](#b1-setting-parallelism-(设置并行度))
        * [b1.1. Operator Level (算子层次)](#b11-operator-level-(算子层次))
        * [b1.2. Execution Environment Level (执行环境层次)](#b12-execution-environment-level-(执行环境层次))
        * [b1.3. Client Level  (客户端层次)](#b13-client-level-(客户端层次))
        * [b1.4. System Level (系统层次)](#b14-system-level-(系统层次))
      - [b2、Task Failure Recovery (Task 故障恢复)](#b2-task-failure-recovery-(Task 故障恢复))
        * [b2.1. Restart Strategies (重启策略)](#b21-restart-strategies-(重启策略))
          + [b.2.1.1. 固定延时重启策略](#b211-固定延时重启策略)
          + [b.2.1.2. 故障率重启策略](#b212-故障率重启策略)
          + [b.2.1.3. 不重启策略](#b213-不重启策略)
          + [b.2.1.4. 备用重启策略](#b214-备用重启策略)
        * [b2.2. Failover Strategies (故障恢复策略)](#b22-failover-strategies-(故障恢复策略))
          + [b.2.2.1. 全图重启故障恢复策略](#b221-全图重启故障恢复策略)
          + [b.2.2.2. 基于 Region 的局部重启故障恢复策略](#b222-基于-region-的局部重启故障恢复策略)
    + [c. Slots and Resources](#c-slots-and-resources)
  * [2.4 参考资料](#24 参考资料)

<small><i><a href='http://ecotrust-canada.github.io/markdown-toc/'>Table of contents generated with markdown-toc</a></i></small>

## 2.1 Layered APIs 

Flink 根据抽象程度分层，提供了三种不同的 API。每一种 API 在简洁性和表达力上有着不同的侧重，并且针对不同的应用场景。
![img](https://flink.apache.org/img/api-stack.png)


### a. Stateful Stream Processing


[ProcessFunction](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/process_function.html) 是 Flink 所提供的最具表达力的接口。ProcessFunction 可以处理一或两条输入数据流中的单个事件或者归入一个特定窗口内的多个事件。它提供了对于时间和状态的细粒度控制。开发者可以在其中任意地修改状态，也能够注册定时器用以在未来的某一时刻触发回调函数。因此，你可以利用 ProcessFunction 实现许多[有状态的事件驱动应用](https://flink.apache.org/zh/usecases.html#eventDrivenApps)所需要的基于单个事件的复杂业务逻辑。

### b. DataStream API 

[DataStream API](https://ci.apache.org/projects/flink/flink-docs-stable/dev/datastream_api.html) 为许多通用的流处理操作提供了处理原语。这些操作包括窗口、逐条记录的转换操作，在处理事件时进行外部数据库查询等。DataStream API 支持 Java 和 Scala 语言，预先定义了例如`map()`、`reduce()`、`aggregate()` 等函数。你可以通过扩展实现预定义接口或使用 Java、Scala 的 lambda 表达式实现自定义的函数。

### c. SQL - Table API

Flink 支持两种关系型的 API，[Table API 和 SQL](https://ci.apache.org/projects/flink/flink-docs-stable/dev/table/index.html)。这两个 API 都是批处理和流处理统一的 API，这意味着在无边界的实时数据流和有边界的历史记录数据流上，关系型 API 会以相同的语义执行查询，并产生相同的结果。Table API 和 SQL 借助了 [Apache Calcite](https://calcite.apache.org/) 来进行查询的解析，校验以及优化。它们可以与 DataStream 和 DataSet API 无缝集成，并支持用户自定义的标量函数，聚合函数以及表值函数。

Flink 的关系型 API 旨在简化[数据分析](https://flink.apache.org/zh/usecases.html#analytics)、[数据流水线和 ETL 应用](https://flink.apache.org/zh/usecases.html#pipelines)的定义。

## 2.2 Components of a Flink Setup 

- JobManager (also called masters )

- TaskManager(also called workers)

- Clients

Flink 运行时包含两类进程：

- **JobManagers** （也称为 *masters*）协调分布式计算。它们负责调度任务、协调 checkpoints、协调故障恢复等。
  每个 Job 至少会有一个 JobManager。高可用部署下会有多个 JobManagers，其中一个作为 *leader*，其余处于 *standby* 状态。
- **TaskManagers**（也称为 *workers*）执行 dataflow 中的 *tasks*（准确来说是 subtasks ），并且缓存和交换数据 *streams*。
  每个 Job 至少会有一个 TaskManager。
JobManagers 和 TaskManagers 有多种启动方式：直接在机器上启动（该集群称为 [standalone cluster](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/ops/deployment/cluster_setup.html)），在容器或资源管理框架，如 [YARN](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/ops/deployment/yarn_setup.html) 或 [Mesos](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/ops/deployment/mesos.html)，中启动。TaskManagers 连接到 JobManagers，通知后者自己可用，然后开始接手被分配的工作。

**客户端**虽然不是运行时（runtime）和作业执行时的一部分，但它是被用作准备和提交 dataflow 到 JobManager 的。提交完成之后，客户端可以断开连接，也可以保持连接来接收进度报告。客户端既可以作为触发执行的 Java / Scala 程序的一部分，也可以在命令行进程中运行`./bin/flink run ...`。
![The processes involved in executing a Flink dataflow](https://ci.apache.org/projects/flink/flink-docs-release-1.9/fig/processes.svg)
## 2.3 Task Execution
### a. Operators 任务和算子链

分布式计算中，Flink 将算子（operator）的 subtask *链接（chain）*成 task。每个 task 由一个线程执行。把算子链接成 tasks 能够减少线程间切换和缓冲的开销，在降低延迟的同时提高了整体吞吐量。链接操作的配置详情可参考：[chaining docs](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/stream/operators/#task-chaining-and-resource-groups)

下图的 dataflow 由五个 subtasks 执行，因此具有五个并行线程。

![Operator chaining into Tasks](https://ci.apache.org/projects/flink/flink-docs-release-1.9/fig/tasks_chains.svg)

### b. Tasks

#### b1. Setting Parallelism (设置并行度)

一个 Flink 程序由多个任务 task 组成（转换/算子、数据源和数据接收器）。一个 task 包括多个并行执行的实例，且每一个实例都处理 task 输入数据的一个子集。一个 task 的并行实例数被称为该 task 的 *并行度* (parallelism)。

使用 [savepoints](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/ops/state/savepoints.html) 时，应该考虑设置最大并行度。当作业从一个 savepoint 恢复时，你可以改变特定算子或着整个程序的并行度，并且此设置会限定整个程序的并行度的上限。由于在 Flink 内部将状态划分为了 key-groups，且性能所限不能无限制地增加 key-groups，因此设定最大并行度是有必要的。

设置 tasks 并行度，优先级由大到小方法及

- Operator Level (算子层次)
- Execution Environment Level  (执行环境层次)
- Client Level (客户端层次)
- System Level  (系统层次)

##### b1.1. Operator Level (算子层次)

单个算子、数据源和数据接收器的并行度可以通过调用 `setParallelism()`方法来指定。

```java
final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

DataStream<String> text = [...]
DataStream<Tuple2<String, Integer>> wordCounts = text
    .flatMap(new LineSplitter())
    .keyBy(0)
    .timeWindow(Time.seconds(5))
    .sum(1).setParallelism(5);

wordCounts.print();

env.execute("Word Count Example");
```

##### b1.2. Execution Environment Level (执行环境层次)

如[此节](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/api_concepts.html#anatomy-of-a-flink-program)所描述，Flink 程序运行在执行环境的上下文中。执行环境为所有执行的算子、数据源、数据接收器 (data sink) 定义了一个默认的并行度。可以显式配置算子层次的并行度去覆盖执行环境的并行度。

可以通过调用 `setParallelism()` 方法指定执行环境的默认并行度。如果想以并行度`3`来执行所有的算子、数据源和数据接收器。可以在执行环境上设置默认并行度，如下所示：

```java
final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
env.setParallelism(3);

DataStream<String> text = [...]
DataStream<Tuple2<String, Integer>> wordCounts = [...]
wordCounts.print();

env.execute("Word Count Example");
```



##### b1.3. Client Level (客户端层次)

将作业提交到 Flink 时可在客户端设定其并行度。客户端可以是 Java 或 Scala 程序，Flink 的命令行接口（CLI）就是一种典型的客户端。

在 CLI 客户端中，可以通过 `-p` 参数指定并行度，例如：

```bash
./bin/flink run -p 10 ../examples/*WordCount-java*.jar
```

在 Java 程序中，可以通过如下方式指定并行度：

```java
try {
    PackagedProgram program = new PackagedProgram(file, args);
    InetSocketAddress jobManagerAddress = RemoteExecutor.getInetFromHostport("localhost:6123");
    Configuration config = new Configuration();

    Client client = new Client(jobManagerAddress, config, program.getUserCodeClassLoader());

    // set the parallelism to 10 here
    client.run(program, 10, true);

} catch (ProgramInvocationException e) {
    e.printStackTrace();
}
```



##### b1.4. System Level (系统层次)

可以通过设置 `./conf/flink-conf.yaml` 文件中的 `parallelism.default` 参数，在系统层次来指定所有执行环境的默认并行度。你可以通过查阅[配置文档](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/ops/config.html)获取更多细节。

b1.5 设置最大并行度

最大并行度可以在所有设置并行度的地方进行设定（客户端和系统层次除外）。与调用 `setParallelism()` 方法修改并行度相似，你可以通过调用 `setMaxParallelism()` 方法来设定最大并行度。

默认的最大并行度等于将 `operatorParallelism + (operatorParallelism / 2)` 值四舍五入到大于等于该值的一个整型值，并且这个整型值是 `2` 的幂次方，注意默认最大并行度下限为 `128`，上限为 `32768`。

**注意** 为最大并行度设置一个非常大的值将会降低性能，因为一些 state backends 需要维持内部的数据结构，而这些数据结构将会随着 key-groups 的数目而扩张（key-group 是状态重新分配的最小单元）。

#### b2. Task Failure Recovery (Task 故障恢复)

当 Task 发生故障时，Flink 需要重启出错的 Task 以及其他受到影响的 Task ，以使得作业恢复到正常执行状态。

Flink 通过重启策略和故障恢复策略来控制 Task 重启：重启策略决定是否可以重启以及重启的间隔；故障恢复策略决定哪些 Task 需要重启。

##### b2.1. Restart Strategies (重启策略)
Flink 作业如果没有定义重启策略，则会遵循集群启动时加载的默认重启策略。 如果提交作业时设置了重启策略，该策略将覆盖掉集群的默认策略。

通过 Flink 的配置文件 `flink-conf.yaml` 来设置默认的重启策略。配置参数 *restart-strategy* 定义了采取何种策略。 如果没有启用 checkpoint，就采用“不重启”策略。如果启用了 checkpoint 且没有配置重启策略，那么就采用固定延时重启策略， 此时最大尝试重启次数由 `Integer.MAX_VALUE` 参数设置。下表列出了可用的重启策略和与其对应的配置值。

每个重启策略都有自己的一组配置参数来控制其行为。 这些参数也在配置文件中设置。 后文的描述中会详细介绍每种重启策略的配置项。

| 重启策略         | restart-strategy 配置值 |
| :--------------- | :---------------------- |
| 固定延时重启策略 | fixed-delay             |
| 故障率重启策略   | failure-rate            |
| 不重启策略       | none                    |

除了定义默认的重启策略以外，还可以为每个 Flink 作业单独定义重启策略。 这个重启策略通过在程序中的 `ExecutionEnvironment` 对象上调用 `setRestartStrategy` 方法来设置。 当然，对于 `StreamExecutionEnvironment` 也同样适用。

下例展示了如何给我们的作业设置固定延时重启策略。 如果发生故障，系统会重启作业 3 次，每两次连续的重启尝试之间等待 10 秒钟。

```java
ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();
env.setRestartStrategy(RestartStrategies.fixedDelayRestart(
  3, // 尝试重启的次数
  Time.of(10, TimeUnit.SECONDS) // 延时
));
```

以下部分详细描述重启策略的配置项。

###### b.2.1.1. 固定延时重启策略

固定延时重启策略按照给定的次数尝试重启作业。 如果尝试超过了给定的最大次数，作业将最终失败。 在连续的两次重启尝试之间，重启策略等待一段固定长度的时间。

通过在 `flink-conf.yaml` 中设置如下配置参数，默认启用此策略。

```yaml
restart-strategy: fixed-delay
```

| 配置参数                                | 描述                                                         | 默认配置值                                                   |
| :-------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| `restart-strategy.fixed-delay.attempts` | 作业宣告失败之前 Flink 重试执行的最大次数                    | 启用 checkpoint 的话是 `Integer.MAX_VALUE`，否则是 1         |
| `restart-strategy.fixed-delay.delay`    | 延时重试意味着执行遭遇故障后，并不立即重新启动，而是延后一段时间。当程序与外部系统有交互时延时重试可能会有所帮助，比如程序里有连接或者挂起的事务的话，在尝试重新执行之前应该等待连接或者挂起的事务超时。 | 启用 checkpoint 的话是 10 秒，否则使用 `akka.ask.timeout` 的值 |

例如：

```yaml
restart-strategy.fixed-delay.attempts: 3
restart-strategy.fixed-delay.delay: 10 s
```

固定延迟重启策略也可以在程序中设置：

```java
ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();
env.setRestartStrategy(RestartStrategies.fixedDelayRestart(
  3, // 尝试重启的次数
  Time.of(10, TimeUnit.SECONDS) // 延时
));
```

###### b.2.1.2. 故障率重启策略

故障率重启策略在故障发生之后重启作业，但是当**故障率**（每个时间间隔发生故障的次数）超过设定的限制时，作业会最终失败。 在连续的两次重启尝试之间，重启策略等待一段固定长度的时间。

通过在 `flink-conf.yaml` 中设置如下配置参数，默认启用此策略。

```yaml
restart-strategy: failure-rate
```

| 配置参数                                                | 描述                             | 配置默认值       |
| :------------------------------------------------------ | :------------------------------- | :--------------- |
| restart-strategy.failure-rate.max-failures-per-interval | 单个时间间隔内允许的最大重启次数 | 1                |
| restart-strategy.failure-rate.failure-rate-interval     | 测量故障率的时间间隔             | 1 分钟           |
| restart-strategy.failure-rate.delay                     | 连续两次重启尝试之间的延时       | akka.ask.timeout |

例如：

```yaml
restart-strategy.failure-rate.max-failures-per-interval: 3
restart-strategy.failure-rate.failure-rate-interval: 5 min
restart-strategy.failure-rate.delay: 10 s
```

故障率重启策略也可以在程序中设置：

```java
ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();
env.setRestartStrategy(RestartStrategies.failureRateRestart(
  3, // 每个时间间隔的最大故障次数
  Time.of(5, TimeUnit.MINUTES), // 测量故障率的时间间隔
  Time.of(10, TimeUnit.SECONDS) // 延时
));
```

###### b.2.1.3. 不重启策略

作业直接失败，不尝试重启。

```yaml
restart-strategy: none
```

不重启策略也可以在程序中设置：

```java
ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();
env.setRestartStrategy(RestartStrategies.noRestart());
```

###### b.2.1.4. 备用重启策略

使用群集定义的重启策略。 这对于启用了 checkpoint 的流处理程序很有帮助。 如果没有定义其他重启策略，默认选择固定延时重启策略。

##### b2.2. Failover Strategies (故障恢复策略)
Flink 支持多种不同的故障恢复策略，该策略需要通过 Flink 配置文件 `flink-conf.yaml` 中的 *jobmanager.execution.failover-strategy* 配置项进行配置。

| 故障恢复策略           | jobmanager.execution.failover-strategy 配置值 |
| :--------------------- | :-------------------------------------------- |
| 全图重启               | full                                          |
| 基于 Region 的局部重启 | region                                        |

###### b.2.2.1. 全图重启故障恢复策略

在全图重启故障恢复策略下，Task 发生故障时会重启作业中的所有 Task 进行故障恢复。

###### b.2.2.2. 基于 Region 的局部重启故障恢复策略

该策略会将作业中的所有 Task 划分为数个 Region。当有 Task 发生故障时，它会尝试找出进行故障恢复需要重启的最小 Region 集合。 相比于全局重启故障恢复策略，这种策略在一些场景下的故障恢复需要重启的 Task 会更少。

此处 Region 指以 Pipelined 形式进行数据交换的 Task 集合。也就是说，Batch 形式的数据交换会构成 Region 的边界。

- DataStream 和 流式 Table/SQL 作业的所有数据交换都是 Pipelined 形式的。
- 批处理式 Table/SQL 作业的所有数据交换默认都是 Batch 形式的。
- DataSet 作业中的数据交换形式会根据 [ExecutionConfig](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/execution_configuration.html) 中配置的 [ExecutionMode](https://ci.apache.org/projects/flink/flink-docs-release-1.9/api/java/org/apache/flink/api/common/ExecutionMode.html) 决定。

需要重启的 Region 的判断逻辑如下：

1. 出错 Task 所在 Region 需要重启。
2. 如果要重启的 Region 需要消费的数据有部分无法访问（丢失或损坏），产出该部分数据的 Region 也需要重启。
3. 需要重启的 Region 的下游 Region 也需要重启。这是出于保障数据一致性的考虑，因为一些非确定性的计算或者分发会导致同一个 Result Partition 每次产生时包含的数据都不相同。

### c. Slots and Resources  

每个 worker（TaskManager）都是一个 *JVM 进程*，并且可以在不同的线程中执行一个或多个 subtasks。为了控制 worker 接收 task 的数量，worker 拥有所谓的 **task slots** （至少一个）。

每个 *task slots* 代表 TaskManager 的一份固定资源子集。例如，具有三个 slots 的 TaskManager 会将其管理的内存资源分成三等份给每个 slot。 划分资源意味着 subtask 之间不会竞争资源，但是也意味着它们只拥有固定的资源。注意这里并没有 CPU 隔离，当前 slots 之间只是划分任务的内存资源。

通过调整 slot 的数量，用户可以决定 subtasks 的隔离方式。每个 TaskManager 有一个 slot 意味着每组 task 在一个单独的 JVM 中运行（例如，在一个单独的容器中启动）。拥有多个 slots 意味着多个 subtasks 共享同一个 JVM。 Tasks 在同一个 JVM 中共享 TCP 连接（通过多路复用技术）和心跳信息（heartbeat messages）。它们还可能共享数据集和数据结构，从而降低每个 task 的开销。

![A TaskManager with Task Slots and Tasks](https://ci.apache.org/projects/flink/flink-docs-release-1.9/fig/tasks_slots.svg)

默认情况下，Flink 允许 subtasks 共享 slots，即使它们是不同 tasks 的 subtasks，只要它们来自同一个 job。因此，一个 slot 可能会负责这个 job 的整个管道（pipeline）。允许 *slot sharing* 有两个好处：

- Flink 集群需要与 job 中使用的最高并行度一样多的 slots。这样不需要计算作业总共包含多少个 tasks（具有不同并行度）。
- 更好的资源利用率。在没有 slot sharing 的情况下，简单的 subtasks（*source/map()*）将会占用和复杂的 subtasks （*window*）一样多的资源。通过 slot sharing，将示例中的并行度从 2 增加到 6 可以充分利用 slot 的资源，同时确保繁重的 subtask 在 TaskManagers 之间公平地获取资源。

![TaskManagers with shared Task Slots](https://ci.apache.org/projects/flink/flink-docs-release-1.9/fig/slot_sharing.svg)

APIs 还包含了 *[resource group](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/stream/operators/#task-chaining-and-resource-groups)* 机制，它可以用来防止不必要的 slot sharing。

根据经验，合理的 slots 数量应该和 CPU 核数相同。在使用超线程（hyper-threading）时，每个 slot 将会占用 2 个或更多的硬件线程上下文（hardware thread contexts）。



## 2.4 参考资料

* [Apache Flink 是什么？-应用](https://flink.apache.org/zh/flink-applications.html)
* [分布式运行时环境](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/concepts/runtime.html)
* [并行执行](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/parallel.html)
* [Task 故障恢复](https://ci.apache.org/projects/flink/flink-docs-release-1.9/zh/dev/task_failure_recovery.html)
* [Apache Flink：特性、概念、组件栈、架构及原理分析](http://shiyanjun.cn/archives/1508.html)

