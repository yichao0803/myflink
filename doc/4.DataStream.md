# 4.DataStream

**Flink 运行模型**

![图 Flink查询模型](https://github.com/yichao0803/myflink/raw/master/image/4StreamExecutionEnvironment-2.png)

以上为 Flink 的运行模型，Flink 的程序主要由三部分构成，分别为 Source、Transformation、Sink。DataSource 主要负责数据的读取，Transformation 主要负责对属于的转换操作，Sink 负责最终数据的输出。

**Flink 程序架构**

每个 Flink 程序都包含以下的若干流程：

- 获得一个执行环境；（Execution Environment）
- 加载/创建初始数据；（Source）
- 指定转换这些数据；（Transformation）
- 指定放置计算结果的位置；（Sink）
- 触发程序执行。

## 4.1 安装环境 Environment (Local and Remote)

执行环境 StreamExecutionEnvironment 是所有 Flink 程序的基础。

创建执行环境有三种方式，分别为：

```java
StreamExecutionEnvironment.getExecutionEnvironment 
StreamExecutionEnvironment.createLocalEnvironment 
StreamExecutionEnvironment.createRemoteEnvironment
```

* StreamExecutionEnvironment.getExecutionEnvironment

创建一个执行环境，表示当前执行程序的上下文。 如果程序是独立调用的，则此方法返回本地执行环境；如果从命令行客户端调用程序以提交到集群，则此方法返回此集群的执行环境，也就是说，getExecutionEnvironment 会根据查询运行的方式决定返回什么样的运行环境，是最常用的一种创建执行环境的方式。

* StreamExecutionEnvironment.createLocalEnvironment

返回本地执行环境，需要在调用时指定默认的并行度。


* StreamExecutionEnvironment.createRemoteEnvironment

返回集群执行环境，将Jar提交到远程服务器。需要在调用时指定JobManager的IP和端口号，并指定要在集群中运行的Jar包。




![StreamExecutionEnvironment](https://github.com/yichao0803/myflink/raw/master/image/4StreamExecutionEnvironment-01.png)


## 4.2 数据源 Source 
### 4.2.1 内置数据源 (readTextFile,fromCollection,etc)

源是程序读取其输入的位置。您可以使用将源附加到程序`StreamExecutionEnvironment.addSource(sourceFunction)`。Flink附带了许多预先实现的源函数，但是您始终可以通过实现`SourceFunction` for非并行源，实现`ParallelSourceFunction`接口或扩展 `RichParallelSourceFunction`for并行源来编写自己的自定义源。

可从以下位置访问几个预定义的流源`StreamExecutionEnvironment`：

**1、基于文件：**

- `readTextFile(path)`- `TextInputFormat`逐行读取文本文件，即符合规范的文件，并将其作为字符串返回。

- `readFile(fileInputFormat, path)` -根据指定的文件输入格式读取（一次）文件。

- `readFile(fileInputFormat, path, watchType, interval, pathFilter, typeInfo)`-这是前两个内部调用的方法。它`path`根据给定的读取文件`fileInputFormat`。根据提供的内容`watchType`，此源可以定期（每`interval`ms）监视路径中的新数据（`FileProcessingMode.PROCESS_CONTINUOUSLY`），或处理一次路径中当前的数据并退出（`FileProcessingMode.PROCESS_ONCE`）。使用`pathFilter`，用户可以进一步从文件中排除文件。

  *实施：*

  在后台，Flink将文件读取过程分为两个子任务，即*目录监视*和*数据读取*。这些子任务中的每一个都是由单独的实体实现的。监视由单个**非并行**（并行度= 1）任务实现，而读取由并行运行的多个任务执行。后者的并行性等于作业并行性。单个监视任务的作用是扫描目录（根据定期扫描或仅扫描一次`watchType`），找到要处理的文件，将它们*分成多个部分*，并将这些拆分分配给下游阅读器。读者将是阅读实际数据的人。每个拆分只能由一个阅读器读取，而阅读器可以一一阅读多个拆分。

  *重要笔记：*

  1. 如果将`watchType`设置为`FileProcessingMode.PROCESS_CONTINUOUSLY`，则在修改文件时，将完全重新处理其内容。这可能会破坏“完全一次”的语义，因为在文件末尾附加数据将导致重新处理其**所有**内容。
  2. 如果将`watchType`设置为`FileProcessingMode.PROCESS_ONCE`，则源将扫描路径**一次**并退出，而无需等待读取器完成文件内容的读取。当然，读者将继续阅读，直到读取了所有文件内容。关闭源将导致在该点之后没有更多检查点。这可能导致节点故障后恢复速度变慢，因为作业将从上一个检查点恢复读取。

**2、基于套接字：**

- `socketTextStream`-从套接字读取。元素可以由定界符分隔。

**3、基于集合：**

- `fromCollection(Collection)`-从Java Java.util.Collection创建数据流。集合中的所有元素必须具有相同的类型。
- `fromCollection(Iterator, Class)`-从迭代器创建数据流。该类指定迭代器返回的元素的数据类型。
- `fromElements(T ...)`-从给定的对象序列创建数据流。所有对象必须具有相同的类型。
- `fromParallelCollection(SplittableIterator, Class)`-从迭代器并行创建数据流。该类指定迭代器返回的元素的数据类型。
- `generateSequence(from, to)` -并行生成给定间隔中的数字序列。

### 4.2.2 自定义数据源 (addSource)

- `addSource`-附加新的源功能。例如，要阅读Apache Kafka，可以使用 `addSource(new FlinkKafkaConsumer010<>(...))`。有关更多详细信息，请参见[连接器](https://ci.apache.org/projects/flink/flink-docs-master/dev/connectors/index.html)。

## 4.3 数据汇 Sink 
###  4.3.1 内置输出  (writeAsText,writeAsCsv,etc)

数据接收器使用`DataStream`，并将其转发到文件，套接字，外部系统或打印它们。Flink带有各种内置的输出格式，这些格式封装在`DataStream`的操作后面：

   - `writeAsText()`/ `TextOutputFormat`-将元素按行写为字符串。通过调用每个元素的*toString（）*方法获得字符串。
   - `writeAsCsv(...)`/ `CsvOutputFormat`-将元组写为逗号分隔的值文件。行和字段定界符是可配置的。每个字段的值来自对象的*toString（）*方法。
   - `print()`/ `printToErr()` - 在标准输出/标准错误流上打印每个元素的*toString（）*值。可选地，可以提供前缀（msg），该前缀在输出之前。这可以帮助区分不同的*打印*调用。如果并行度大于1，则输出之前还将带有产生输出的任务的标识符。
   - `writeUsingOutputFormat()`/ `FileOutputFormat`-自定义文件输出的方法和基类。支持自定义对象到字节的转换。
   - `writeToSocket` -根据以下内容将元素写入套接字 `SerializationSchema`
   - `addSink`-调用自定义接收器功能。Flink捆绑有连接到其他系统（例如Apache Kafka）的连接器，这些连接器实现为接收器功能。

请注意，上的`write*()`方法`DataStream`主要用于调试目的。它们不参与Flink的检查点，这意味着这些功能通常具有至少一次的语义。刷新到目标系统的数据取决于OutputFormat的实现。这意味着并非所有发送到OutputFormat的元素都立即显示在目标系统中。同样，在失败的情况下，这些记录可能会丢失。

为了将流可靠，准确地一次传输到文件系统中，请使用`flink-connector-filesystem`。同样，通过该`.addSink(...)`方法的自定义实现可以参与Flink一次精确语义的检查点。

  * Custom Source(addSink)

## 4.4 转换算子 Transformations

### 4.4.1 基本算子 

* Map [DataStream->DataStream]：一对一转换,即一条转换成另一条。
* Filter [DataStream->DataStream]：过滤出需要的数据
* FlatMap [DataStream->DataStream]：一行变零到多行。

### 4.4.2 分组算子 KeyedStream Transformations

* KeyBy [DataStream->KeyedStream] ：按指定的 Key 对数据重分区。将同一 Key 的数据放到同一个分区。在内部 *keyBy（）* 是通过哈希分区实现的  
  **注意：**
* 分区结果和 KeyBy 下游算子的并行度强相关。如下游算子只有一个并行度,不管怎么分，都会分到一起。
  * 对于 POJO 类型，KeyBy 可以通过 keyBy(fieldName) 指定字段进行分区。
  * 对于 Tuple 类型，KeyBy可以通过 keyBy(fieldPosition) 指定字段进行分区。
  * 对于一般类型，如上, KeyBy可 以通过 keyBy(new KeySelector {...}) 指定字段进行分区。
  
* Aggregations  [KeyedStream->DataStream]：Aggregate 对 KeyedStream 按指定字段滚动聚合并输出每一次滚动聚合后的结果。默认的聚合函数有:sum、min、minBy、max、mabBy。
 **注意：**        
 * max(field) 与 maxBy(field) 的区别: maxBy 可以返回 field 最大的那条数据;而 max 则是将最大的 field 的值赋值给第一条数据并返回第一条数据。同理, min与 minBy。
 * Aggregate 聚合算子会滚动输出每一次聚合后的结果。

* Reduce [KeyedStream->DataStream]：基于 ReduceFunction 进行滚动聚合，并向下游算子输出每次滚动聚合后的结果。
### 4.4.3 多流算子 Multistream Transformations

* Union

在`DataStream`上使用`union`算子可以合并多个同类型的数据流，并生成同类型的数据流，即可以将多个`DataStream[T]`合并为一个新的`DataStream[T]`。数据将按照先进先出（First In First Out）的模式合并，且不去重。下图`union`对白色和深色两个数据流进行合并，生成一个数据流。

![hywpvume62](https://github.com/yichao0803/myflink/raw/master/image/4StreamExecutionEnvironment-3.png)

* Connect, coMap, coFlatMap

`union`虽然可以合并多个数据流，但有一个限制，即多个数据流的数据类型必须相同。`connect`提供了和`union`类似的功能，用来连接两个数据流，它与`union`的区别在于：

1. `connect`只能连接两个数据流，`union`可以连接多个数据流。
2. `connect`所连接的两个数据流的数据类型可以不一致，`union`所连接的两个数据流的数据类型必须一致。
3. 两个`DataStream`经过`connect`之后被转化为`ConnectedStreams`，`ConnectedStreams`会对两个流的数据应用不同的处理方法，且双流之间可以共享状态。

`connect`经常被应用在对一个数据流使用另外一个流进行控制处理的场景上，如下图所示。控制流可以是阈值、规则、机器学习模型或其他参数。

![j1ijb8m8ds](https://github.com/yichao0803/myflink/raw/master/image/4StreamExecutionEnvironment-4.png)

* Split & select

### 4.4.4 物理分区操作 Distribution Transformations 

物理分区（Physical Partitioning）操作的作用是根据指定的分区策略将数据重新分配到不同节点的Task案例上执行。当使用DataStream提供的API对数据处理过程中，依赖于算子本身对数据的分区控制，如果用户希望自己控制数据分区，例如当数据发生了数据倾斜的时候，就需要通过定义物理分区策略的方式对数据集进行重新分布处理。Flink中已经提供了常见的分区策略，例如随机分区（Random Partitioning）、平衡分区（Roundobin Partitioning）、按比例分区（RoundrobinPartitioning）等。当然如果给定的分区策略无法满足需求，也可以根据Flink提供的分区控制接口创建分区器，实现自定义分区控制。

* **Global:** 上游算子将所有记录发送给下游算子的第一个实例。
* **Broadcast:** 上游算子将每一条记录发送给下游算子的所有实例。
* **Forward：**只适用于上游算子实例数与下游算子相同时，每个上游算子实例将记录发送给下游算子对应的实例。
* **Shuffle：**上游算子对每条记录随机选择一个下游算子进行发送。
* **Rebalance：**上游算子通过轮询的方式发送数据。
* **Rescale：**当上游和下游算子的实例数为 n 或 m 时，如果 n < m，则每个上游实例向ceil(m/n)或floor(m/n)个下游实例轮询发送数据；如果 n > m，则 floor(n/m) 或 ceil(n/m) 个上游实例向下游实例轮询发送数据。
* **PartitionCustomer：**当上述内置分配方式不满足需求时，用户还可以选择自定义分组方式。


## 4.5 数据类型 Data Types

### 4.5.1 Flink 中的类型处理

Flink 会尽力推断有关数据类型的大量信息，这些数据会在分布式计算期间被网络交换或存储。 可以把它想象成一个推断表结构的数据库。在大多数情况下，Flink 可以依赖自身透明的推断出所有需要的类型信息。 掌握这些类型信息可以帮助 Flink 实现很多意想不到的特性：

- 对于使用 POJOs 类型的数据，可以通过指定字段名（比如 `dataSet.keyBy("username")` ）进行 grouping 、joining、aggregating 操作。 类型信息可以帮助 Flink 在运行前做一些拼写错误以及类型兼容方面的检查，而不是等到运行时才暴露这些问题。
- Flink 对数据类型了解的越多，序列化和数据布局方案就越好。 这对 Flink 中的内存使用范式尤为重要（可以尽可能处理堆上或者堆外的序列化数据并且使序列化操作很廉价）。
- 最后，它还使用户在大多数情况下免于担心序列化框架以及类型注册。

通常在应用*运行之前的阶段 (pre-flight phase)*，需要数据的类型信息 - 也就是在程序对 `DataStream` 或者 `DataSet` 的操作调用之后，在 `execute()`、`print()`、`count()`、`collect()` 调用之前。

### 4.5.2  Flink 的 TypeInformation 类

  * 类 [TypeInformation](https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/typeinfo/TypeInformation.java) 是所有类型描述符的基类。该类表示类型的基本属性，并且可以生成序列化器，在一些特殊情况下可以生成类型的比较器。 (*请注意，Flink 中的比较器不仅仅是定义顺序 - 它们是处理键的基础工具*)

    Flink 内部对类型做了如下区分：

    - 基础类型：所有的 Java 主类型（primitive）以及他们的包装类，再加上 `void`、`String`、`Date`、`BigDecimal` 以及 `BigInteger`。
    - 主类型数组（primitive array）以及对象数组
    - 复合类型
      - Flink 中的 Java 元组 (Tuples) (元组是 Flink Java API 的一部分)：最多支持25个字段，null 是不支持的。
      - Scala 中的 *case classes* (包括 Scala 元组)：null 是不支持的。
      - Row：具有任意数量字段的元组并且支持 null 字段。。
      - POJOs: 遵循某种类似 bean 模式的类。
    - 辅助类型 (Option、Either、Lists、Maps 等)
    - 泛型类型：这些不是由 Flink 本身序列化的，而是由 Kryo 序列化的。

    POJOs 是特别有趣的，因为他们支持复杂类型的创建以及在键的定义中直接使用字段名： `dataSet.join(another).where("name").equalTo("personName")` 它们对运行时也是透明的，并且可以由 Flink 非常高效地处理。

    #### POJO 类型的规则

    如果满足以下条件，Flink 会将数据类型识别为 POJO 类型（并允许“按名称”引用字段）：

    - 该类是公有的 (public) 和独立的（没有非静态内部类）
    - 该类拥有公有的无参构造器
    - 类（以及所有超类）中的所有非静态、非 transient 字段都是公有的（非 final 的）， 或者具有遵循 Java bean 对于 getter 和 setter 命名规则的公有 getter 和 setter 方法。

    请注意，当用户自定义的数据类型无法识别为 POJO 类型时，必须将其作为泛型类型处理并使用 Kryo 进行序列化。

    #### 创建 TypeInformation 或者 TypeSerializer

    要为类型创建 TypeInformation 对象，需要使用特定于语言的方法：

    因为 Java 会擦除泛型类型信息，所以需要将类型传入 TypeInformation 构造函数：

    对于非泛型类型，可以传入类型的 Class 对象：

    ```
    TypeInformation<String> info = TypeInformation.of(String.class);
    ```

    对于泛型类型，你需要通过 `TypeHint` 来“捕获”泛型类型信息：

    ```
    TypeInformation<Tuple2<String, Double>> info = TypeInformation.of(new TypeHint<Tuple2<String, Double>>(){});
    ```

    在内部，这会创建 TypeHint 的匿名子类，捕获泛型信息并会将其保留到运行时。

    通过调用 `TypeInformation` 对象的 `typeInfo.createSerializer(config)` 方法可以简单的创建 `TypeSerializer` 对象。

    `config` 参数的类型是 `ExecutionConfig`，这个参数中持有程序注册的自定义序列化器信息。 尽可能传入程序合适的 ExecutionConfig 。可以通过调用 `DataStream` 或者 `DataSet` 的 `getExecutionConfig()` 函数获得 ExecutionConfig 对象。如果是在一个函数的内部 （比如 `MapFunction`），可以使这个函数首先成为 [RichFunction](https://github.com/apache/flink/blob/master//flink-core/src/main/java/org/apache/flink/api/common/functions/RichFunction.java) ，然后通过调用 `getRuntimeContext().getExecutionConfig()` 获得 ExecutionConfig 对象。
## 4.6 Functions
## 4.7 Iterations

迭代流程序实现了一个步进函数，并将它嵌入到一个`IterativeStream`。由于DataStream程序可能永远不会完成，因此没有最大迭代次数。相反，您需要使用`split`转换或，指定流的哪一部分反馈给迭代，哪一部分向下游转发`filter`。在这里，我们展示了一个使用过滤器的示例。首先，我们定义一个`IterativeStream`

```
IterativeStream<Integer> iteration = input.iterate();
```

然后，我们使用一系列转换（此处为简单`map`转换）指定将在循环内执行的逻辑

```
DataStream<Integer> iterationBody = iteration.map(/* this is executed many times */);
```

要关闭迭代并定义迭代尾部，请调用的`closeWith(feedbackStream)`方法`IterativeStream`。提供给该`closeWith`函数的DataStream 将反馈到迭代头。一种常见的模式是使用过滤器将反馈的部分流和向前传播的部分分开。这些过滤器可以，例如，定义“终止”逻辑，其中元素被允许向下游传播而不是被反馈。

```
iteration.closeWith(iterationBody.filter(/* one part of the stream */));
DataStream<Integer> output = iterationBody.filter(/* some other part of the stream */);
```

例如，以下程序从一系列整数中连续减去1，直到它们达到零为止：

```
DataStream<Long> someIntegers = env.generateSequence(0, 1000);

IterativeStream<Long> iteration = someIntegers.iterate();

DataStream<Long> minusOne = iteration.map(new MapFunction<Long, Long>() {
  @Override
  public Long map(Long value) throws Exception {
    return value - 1 ;
  }
});

DataStream<Long> stillGreaterThanZero = minusOne.filter(new FilterFunction<Long>() {
  @Override
  public boolean filter(Long value) throws Exception {
    return (value > 0);
  }
});

iteration.closeWith(stillGreaterThanZero);

DataStream<Long> lessThanZero = minusOne.filter(new FilterFunction<Long>() {
  @Override
  public boolean filter(Long value) throws Exception {
    return (value <= 0);
  }
});
```



## 4.8 时间概念和 watermark
### 4.8.1 时间概念类型

对于流式数据处理，最大的特点是数据上具有时间的属性特征，Flimk根据时间产生的位置不同，将时间区分为三种时间概念，分别为事件生成时间（Event Time）、事件接入时间（Ingestion Time）和事件处理时间（Processing Time）。如图4-7所示，数据从终端产生，或者从系统中产生的过程中生成的时间为事件生成时间，当数据经过消息中间件传入到Flink系统中，在DataSource中接入的时候会生成事件接入时间，当数据在F link系统中通过各个算子实例执行转换操作的过程中，算子实例所在系统的时间为数据处理时间。Flink已经支持这三种类型时间概念，用户能够根据需要选择时间类型作为对流式数据的依据，这种情况极大地增强了对事件数据处理的灵活性和准确性。

1、处理时间（Processing Time）是指数据在操作算子计算过程中获取到的所在主机时间

2、事件时间（Event Time）是每个独立事件在产生它的设备上发生的时间，这个时间通常在事件进入Flink之前就已经嵌入到事件中，时间顺序取决于事件产生的地方，和下游数据处理系统的时间无关

3、接入时间（Ingestion Time）是数据进入Flink系统的时间，Ingestion Time依赖于Source Operator所在主机的系统时钟

4、指定时间概念 （Assign Timestamps ）

在Flink中默认情况下使用是Process Time时间概念，如果用户选择使用Event Time或者IngestionTime概念，则需要在创建的StreamExecutionEnvironment中调用setStream-TimeCharacteristic()方法设定系统的时间概念，如下代码使用TimeCharacteristic. EventTime作为系统的时间概念，这样对当前的StreamExecutionEnvironment会全局生效。对应的，如果使用Ingestion Time概念，则通过传入TimeCharacteristic. IngestionTime参数指定。

```java
    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();    
        env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);
```

### 4.8.2 Timestamp 分配和 Watermark 生成

Flink 支持两种方式生成 Watermark： 

* 第一种，**在 SourceFunction 中生成**：通过 `collectWithTimestamp(T element, long timestamp)` 方法发送记录的第二个参数 `timestamp ` 即为数据的 EventTime 对应的时间戳 ，同时需要调用emitWatermark()方法生成Watermarks，表示接下来不会再有时间戳小于等于这个数值记录。

  ```
     @Override
          public void run(SourceContext<Tuple2<String, Integer>> ctx) throws Exception {
              Integer counts = 200;
              for (int i = 0; i < counts; i++) {
                  Thread.sleep(200);
                  long currentTimeMillis = System.currentTimeMillis();            
                  ctx.collectWithTimestamp(Tuple2.of(String.format("测试源_%d", i % 3), 1), currentTimeMillis); 
                  ctx.emitWatermark(new Watermark(currentTimeMillis));
              }
          }
  ```

  

* 第二中，**通过  DataStream API  指定**：有时候我们不想在 SourceFunction 里生成 timestamp 或者 watermark，或者说使用的 SourceFunction 本身不支持（比如外部数据源连接器），我们还可以在使用 DataStream API 的时候指定，调用的 DataStream.assignTimestampsAndWatermarks 这个方法，能够接收不同的 timestamp 和 watermark 的生成器。生成器可以分为两类：

  * 第一类是定期生成器；实现接口：AssignerWithPeriodicWatermarks
  * 第二类是根据一些在流处理数据流中遇到的一些特殊记录生成的；实现接口：AssignerWithPunctuatedWatermarks

  ![image-20201019151708496](https://raw.githubusercontent.com/yichao0803/myflink/master/image/\4StreamExecutionEnvironment-6.png)

  大家要注意的是就是我们在分配 timestamp 和生成 watermark 的过程，虽然在 SourceFunction 和 DataStream 中都可以指定，但是还是建议生成的工作越靠近 DataSource 越好。这样会方便让程序逻辑里面更多的 operator 去判断某些数据是否乱序。Flink 内部提供了很好的机制去保证这些 timestamp 和 watermark 被正确地传递到下游的节点。

 

  

  ### 4.8.3 Watermark 传播

  ![4StreamExecutionEnvironment-5](https://raw.githubusercontent.com/yichao0803/myflink/master/image/4StreamExecutionEnvironment-5.png)

  具体的传播策略基本上遵循这三点。

  - 首先，watermark 会以广播的形式在算子之间进行传播。比如说上游的算子，它连接了三个下游的任务，它会把自己当前的收到的 watermark 以广播的形式传到下游。
  - 第二，如果在程序里面收到了一个 Long.MAX_VALUE 这个数值的 watermark，就表示对应的那一条流的一个部分不会再有数据发过来了，它相当于就是一个终止的一个标志。
  - 第三，对于单流而言，这个策略比较好理解，而对于有多个输入的算子，watermark 的计算就有讲究了，一个原则是：单输入取其大，多输入取小。

  举个例子，假设这边蓝色的块代表一个算子的一个任务，然后它有三个输入，分别是 W1、W2、W3，这三个输入可以理解成任何的输入，这三个输入可能是属于同一个流，也可能是属于不同的流。然后在计算 watermark 的时候，对于单个输入而言是取他们的最大值，因为我们都知道 watermark 应该遵循一个单调递增的一个原则。对于多输入，它要统计整个算子任务的 watermark 时，就会取这三个计算出来的 watermark 的最小值。即一个多个输入的任务，它的 watermark 受制于最慢的那条输入流。这一点类似于木桶效应，整个木桶中装的水会就是受制于最矮的那块板。

  watermark 在传播的时候有一个特点是，它的传播是幂等的。多次收到相同的 watermark，甚至收到之前的 watermark 都不会对最后的数值产生影响，因为对于单个输入永远是取最大的，而对于整个任务永远是取一个最小的。

  同时我们可以注意到这种设计其实有一个局限，具体体现在它没有区分你这个输入是一条流多个 partition 还是来自于不同的逻辑上的流的 JOIN。对于同一个流的不同 partition，我们对他做这种强制的时钟同步是没有问题的，因为一开始就是把一条流拆散成不同的部分，但每一个部分之间共享相同的时钟。但是如果算子的任务是在做类似于 JOIN 操作，那么要求你两个输入的时钟强制同步其实没有什么道理的，因为完全有可能是把一条离现在时间很近的数据流和一个离当前时间很远的数据流进行 JOIN，这个时候对于快的那条流，因为它要等慢的那条流，所以说它可能就要在状态中去缓存非常多的数据，这对于整个集群来说是一个很大的性能开销。

  * ProcessFunction 
    * TimeService and Timer
    
    * Emitting to Side Outputs（发射至侧面输出）
    

  

  ## 4.9 Windows

  在每个窗口算子中包含了Windows Assigner、Windows Trigger（窗口触发器）、Evictor（数据剔除器）、Lateness（时延设定）、Output Tag（输出标签）以及Windows Funciton等组成部分，其中Windows Assigner和WindowsFunciton是所有窗口算子必须指定的属性，其余的属性都是根据实际情况选择指定。

  * Windows Assigner：指定窗口的类型，定义如何将数据流分配到一个或多个窗口；
  * Windows Trigger：指定窗口触发的时机，定义窗口满足什么样的条件触发计算；
  * Evictor：用于数据剔除；
  * Lateness：标记是否处理迟到数据，当迟到数据到达窗口中是否触发计算；
  * Output Tag：标记输出标签，然后在通过getSideOutput将窗口中的数据根据标签输出；
  * Windows Funciton：定义窗口上数据处理的逻辑，例如对数据进行sum操作。



 ### 4.9.1  Windows Assigner

#### 1、Keyed和Non-Keyed窗口

​	在运用窗口计算时，Flink根据上游数据集是否为KeyedStream类型（将数据集按照Key分区），对应的Windows Assigner也会有所不同。上游数据集如果是KeyedStream类型，则调用DataStream API的window()方法指定WindowsAssigner，数据会根据Key在不同的Task实例中并行分别计算，最后得出针对每个Key统计的结果。如果是Non-Keyed类型，则调用WindowsAll()方法来指定Windows Assigner，所有的数据都会在窗口算子中路由到一个Task中计算，并得到全局统计结果。

​	从业务层面讲，如果用户选择对Key进行分区，就能够将相同key的数据分配在同一个分区，例如统计同一个用户在五分钟内不同的登录IP地址数。如果用户没有根据指定Key，此时需要对窗口上的数据进行去全局统计计算，这种窗口被称为Global Windows，例如统计某一段时间内某网站所有的请求数。

#### 2、Windows Assigner

##### （1）滚动窗口

如图所示，滚动窗口是根据固定时间或大小进行切分，且窗口和窗口之间的元素互不重叠。这种类型的窗口的最大特点是比较简单，但可能会导致某些有前后关系的数据计算结果不正确，而对于按照固定大小和周期统计某一指标的这种类型的窗口计算就比较适合，同时实现起来也比较方便

DataStream API中提供了基于Event Time和Process Time两种时间类型的Tumbling窗口，对应的Assigner分别为TumblingEventTimeWindows和TumblingProcessTimeWindows。调用DataStream API的Window方法来指定相应的Assigner，并使用每种Assigner的of()方法来定义窗口的大小，其中时间单位可以是Time.milliseconds(x)、Time.seconds(x)或Time.minutes(x)，也可以是不同时间单位的组合。

![image-20201019190251834](https://raw.githubusercontent.com/yichao0803/myflink/master/image/4StreamExecutionEnvironment-7.png)

注意：默认窗口时间的时区是UTC-0，因此UTC-0以外的其他地区均需要通过设定时间偏移量调整时区，在国内需要指定Time.hours（-8）的偏移量

##### （2）滑动窗口

滑动窗口也是一种比较常见的窗口类型，其特点是在滚动窗口基础之上增加了窗口滑动时间（Slide Time），且允许窗口数据发生重叠。如图所示，当Windows size固定之后，窗口并不像滚动窗口按照Windows Size向前移动，而是根据设定的Slide Time向前滑动。窗口之间的数据重叠大小根据Windows size和Slide time决定，当Slide time小于Windows size便会发生窗口重叠，Slide size大于Windows size就会出现窗口不连续，数据可能不能在任何一个窗口内计算，Slide size和Windows size相等时，Sliding Windows其实就是TumblingWindows。滑动窗口能够帮助用户根据设定的统计频率计算指定窗口大小的统计指标，例如每隔30s统计最近10min内活跃用户数等

![4StreamExecutionEnvironment-8](https://raw.githubusercontent.com/yichao0803/myflink/master/image/4StreamExecutionEnvironment-8.png)

DataStream API针对Sliding Windows也提供了不同时间类型的Assigner，其中包括基于Event Time的SlidingEventTimeWindows和基于Process Time的SlidingProcessingTime-Windows。

##### （3）会话窗口

会话窗口（Session Windows）主要是将某段时间内活跃度较高的数据聚合成一个窗口进行计算，窗口的触发的条件是Session Gap，是指在规定的时间内如果没有数据活跃接入，则认为窗口结束，然后触发窗口计算结果。需要注意的是如果数据一直不间断地进入窗口，也会导致窗口始终不触发的情况。与滑动窗口、滚动窗口不同的是，Session Windows不需要有固定windows size和slide time，只需要定义session gap，来规定不活跃数据的时间上限即可。如图4-13所示，通过sessiongap来判断数据是否属于同一活跃数据集，从而将数据切分成不同的窗口进行计算。

![4StreamExecutionEnvironment-9](https://raw.githubusercontent.com/yichao0803/myflink/master/image/4StreamExecutionEnvironment-9.png)

Session Windows窗口类型比较适合非连续型数据处理或周期性产生数据的场景，根据用户在线上某段时间内的活跃度对用户行为数据进行统计。和前面两个窗口一样， DataStream API中可以创建基于Event Time和Process Time的SessionWindows，对应的Assigner分别为EventTimeSessionWindows和ProcessTimeSessionWindows

在创建Session Windows的过程中，除了调用withGap方法输入固定的SessionGap, Flink也能支持动态的调整Session Gap。只需要实现SessionWindowTimeGapExtractor接口，并复写extract方法，完成动态SessionGap的抽取，然后将创建好的Session Gap抽取器传入ProcessingTimeSessionWindows.withDynamic Gap()方法中即可。

注意

由于Session Windows本质上没有固定的起止时间点，因此底层计算逻辑和Tumbliing窗口及Sliding窗口有一定的区别。Session Windows为每个进入的数据都创建了一个窗口，最后再将距离Session Gap最近的窗口进行合并，然后计算窗口结果。因此对于Session Windows来说需要能够合并的Trigger和Windows Funciton，比如ReduceFunction、AggregateFunction、ProcessWindowFunction等

##### （4）全局窗口

全局窗口（Global Windows）将所有相同的key的数据分配到单个窗口中计算结果，窗口没有起始和结束时间，窗口需要借助于Triger来触发计算，如果不对Global Windows指定Triger，窗口是不会触发计算的。因此，使用GlobalWindows需要非常慎重，用户需要非常明确自己在整个窗口中统计出的结果是什么，并指定对应的触发器，同时还需要有指定相应的数据清理机制，否则数据将一直留在内存中

![4StreamExecutionEnvironment-10](https://raw.githubusercontent.com/yichao0803/myflink/master/image/4StreamExecutionEnvironment-10.png)

### 4.9.2、Windows Function

在上一节的学习我们已经了解Flink支持了不同类型窗口的Assigner，对数据集定义了Window Assigner之后，下一步就可以定义窗口内数据的计算逻辑，也就是Window Function的定义。Flink中提供了四种类型的Window Function，分别为ReduceFunction、AggregateFunction、FoldFunction以及ProcessWindowFunction。

四种类型的Window Fucntion按照计算原理的不同可以分为两大类，一类是增量聚合函数，对应有ReduceFunction、AggregateFunction和FoldFunction；另一类是全量窗口函数，对应有ProcessWindowFunction。**增量聚合函数计算性能较高，占用存储空间少**，主要因为基于中间状态的计算结果，窗口中只维护中间结果状态值，不需要缓存原始数据。**而全量窗口函数使用的代价相对较高，性能比较弱**，主要因为此时算子需要对所有属于该窗口的接入数据进行缓存，然后等到窗口触发的时候，对所有的原始数据进行汇总计算。如果接入数据量比较大或窗口时间比较长，就比较有可能导致计算性能的下降。下面将分别对每种WindowFunction在Flink中的使用进行解释和说明。

#### 1、ReduceFunction

   

#### 2、AggregateFunction

   

#### 3、FoldFunction

   

#### 4、ProcessWindowFunction

   

#### 5、Incremental Aggregation和ProcessWindowsFunction整合




#### 6、ProcessWindowFunction状态操作





  * Joining
    * Windows Join 
      * Tumbling Window Join 
      * Sliding Window Join 
      * Session Window Join 
    * Interval Join 
    
    
## 4.10 Async I/O



## 4.11 参考资料

* [operators](https://ci.apache.org/projects/flink/flink-docs-release-1.9/dev/stream/operators/)
* [iterations](https://ci.apache.org/projects/flink/flink-docs-release-1.9/dev/datastream_api.html#iterations)
* [数据类型以及序列化](https://ci.apache.org/projects/flink/flink-docs-release-1.10/zh/dev/types_serialization.html)
* [Flink DataStream 算子 Map、FlatMap、Filter、KeyBy、Reduce、Fold、Aggregate](https://blog.csdn.net/wangpei1949/article/details/101625394)
* [Flink算子使用方法及实例演示：union和connect](https://cloud.tencent.com/developer/article/1560680)
* [Flink 原理与实现：数据流上的类型和操作](http://wuchong.me/blog/2016/05/20/flink-internals-streams-and-operations-on-streams/)
* [Apache Flink 进阶教程（二）：Time 深度解析](https://ververica.cn/developers/advanced-tutorial-2-time-depth-analysis/)
* [Flink原理、实战与性能优化](https://weread.qq.com/web/reader/56332f30718247bd563ee2fk02e32f0021b02e74f10ece8)
* 
